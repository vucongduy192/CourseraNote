{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Giới thiệu Neural Network\n",
    "### Khái niệm:\n",
    "**Neural** là 1 phép biến đổi từ dữ liệu đầu vào, để đưa ra dự đoán đầu ra.\n",
    "<img src=\"images/Neural.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural network** là 1 chuỗi các phép biến đổi.\n",
    "<img src=\"images/Neural_Network_Housing.png\">\n",
    "\n",
    "Xét ví dụ về việc dự đoán giá nhà:\n",
    "* Đầu vào: các feature size, bedrooms, zip code, wealth \n",
    "* Đầu ra : price\n",
    "* 1 hidden layer biểu diễn family size, walkability, school quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khi implement, để cho đơn giản 1 node trong layer sau được biểu diễn qua tất cả các node layer liền trước nó.\n",
    "\n",
    "Ví dụ: family_size = x1 * a + x2 * b + x3 * 0 + x4 * 0 \n",
    "<img src=\"images/Neural_Network_Implement.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Supervised Learning\n",
    "### Khái niệm:  \n",
    "Supervised Learning (học có giám sát) là thuật toán dự đoán đầu ra (outcome) của một dữ liệu mới (new input) dựa trên các cặp (input, outcome) đã biết từ trước.\n",
    "\n",
    "### Phân loại:  \n",
    "* Classification (Phân loại)\n",
    "* Regression (Hồi quy): Nếu label không được chia thành các nhóm mà là một giá trị thực cụ thể.\n",
    "\n",
    "### Kiểu dữ liệu:\n",
    "<img src=\"images/Data_Type.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Binary Classification\n",
    "### Khái niệm: \n",
    "Binary Classification là bài toán phân loại với 2 nhãn có hoặc không.\n",
    "Ví dụ: nhận dạng trong ảnh có chứa mèo hay không ?\n",
    "* Đầu vào: ảnh\n",
    "* Đầu ra : label 1 (cat), 0 (non-cat)\n",
    "\n",
    "<img src=\"images/Cat_Classifier.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu ảnh ở dạng unstructure data, được lưu trong máy tính dưới dạng 3 ma trận R, G, B.\n",
    "\n",
    "Giả sử kích thước ảnh 64x64, thì kích thước feature vector được tính bằng Nx = 64x64x3 = 12288"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dữ liệu huấn luyện\n",
    "Xét tập training gồm m ảnh với nhãn tương ứng.\n",
    "* Feature: ma trận X (Nx, m) với mỗi cột tương ứng với feature vector của 1 ảnh\n",
    "* Label  : ma trận Y (1 , m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Binary_Classification.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Logistic Regression\n",
    "### Khái niệm: \n",
    "Logistic Regression là thuật toán hồi quy, thuộc nhóm supervised learning.\n",
    "\n",
    "Ở đây, hồi quy có thể hiểu như sau. Hồi là quay về , Quy là tổng quát hóa lại thành công thức Y = f(x). Hồi Quy là từ dữ liệu đang có, quy về công thức diễn tả mối quan hệ Y = f(x).\n",
    "\n",
    "### Mô hình: f(x) = f(w^T * x)\n",
    "trong đó:  \n",
    "+ f() được gọi là activation function\n",
    "+ w ma trận trọng số  w.shape = \n",
    "\n",
    "**Hàm sigmoid: 1 / (1 + e^(-z))**\n",
    "\n",
    "**Đặc điểm của hàm sigmoid(z):**\n",
    "* Là hàm đồng biến, có giá trị nằm trong [0, 1]\n",
    "* z càng lớn thì đầu ra càng gần 1\n",
    "* z càng nhỏ thì đầu ra càng gần 0\n",
    "\n",
    "Trong dạng này, đầu ra có thể được thể hiện dưới dạng xác suất (probability). Ví dụ: xác suất thi đỗ nếu biết thời gian ôn thi, xác suất ngày mai có mưa dựa trên những thông tin đo được trong ngày hôm nay,…\n",
    "\n",
    "Đặt đầu ra dự đoán **y^ =  f(w^T * x)**, ta có thể giả sử rằng xác suất để một điểm dữ liệu x rơi vào class 1 là y^, \n",
    "rơi vào class 0 là 1 - y^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Logistic_Model.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V.Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "    \n",
    "   Loss funciton là hàm đặc trưng cho sự sai sót giữa đầu ra dự đoán y^ và giá trị y thực sự. Được tính theo công thức **1/2 (y^ - y)^2**. Trong bài toán Logistic Regression, hàm mất mát được tính theo biểu thức **L = -(ylogy^ + (1-y)log(1-y^))** \n",
    "### Cost Function\n",
    "   Cost function là tổng mất mát trên toàn bộ tập dữ liệu. Được tính bằng tổng sigma các loss function cho từng điểm dữ liệu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Cost_Function.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Recap.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đặt vấn đề\n",
    "   Mục tiêu là tìm ra bộ (w,b) để hàm mất mát đạt giá trị nhỏ nhất. \n",
    "### Phương pháp Gradient Descent\n",
    "   Tìm đạo hàm của hàm mất mát J theo 2 tham số là (w,b). \n",
    "   Learning rate là đại lượng đặc trưng cho tốc độ hồi quy về điểm cực tiểu của hàm Loss Function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Gradient_Descent.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Backward_Calculus.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cách xác định đạo hàm của **J** vs **v** hay vs **a**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Logistic_Regression_Derivative.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muốn tìm đạo hàm của hàm Loss Funciton theo w1, w2, b. Ta cần tìm đạo hàm thông qua các hàm hợp, như là hàm a(sigmoid), hàm z. Thông qua các hàm trung gian để tính đạo hàm theo các biến thành phần. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Logistic_Regression_Derivative_m_example.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization \n",
    "\n",
    "Thực hiện phép toán giữa vector, để nhanh hơn dùng vòng for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcastring trong python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Broadcasting.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
